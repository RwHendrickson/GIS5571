{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab01: Working with APIs\n",
    "\n",
    "By Rob Hendrickson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries\n",
    "\n",
    "# File manipulation\n",
    "\n",
    "import os # For working with Operating System\n",
    "import urllib # For accessing websites\n",
    "import requests # For accessing websites\n",
    "import zipfile # For extracting from Zipfiles\n",
    "from io import BytesIO, StringIO # For reading bytes objects\n",
    "import getpass # Inputting passwords\n",
    "\n",
    "# Analysis\n",
    "\n",
    "import numpy as np # For working with Arrays\n",
    "import pandas as pd # Data Manipulation\n",
    "import geopandas as gpd # Spatial Data Manipulation\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt # Basic Plotting\n",
    "# import seaborn as sns # Statistical Plotting\n",
    "# import contextily # Base Map Visualization\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Ignores some warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definitions\n",
    "\n",
    "cwd = os.getcwd() # Current Working Directory\n",
    "\n",
    "def extract_zip_from_url(url=None):\n",
    "    '''Extract a zipfile from the internet and unpack it in to it's own folder within working directory.\n",
    "    Takes a single url (string).'''\n",
    "    \n",
    "    if type(url) == str: # Single url\n",
    "        # Create folder name for file\n",
    "        folder_name = url.split('/')[-1][:-4]\n",
    "        # Make folder for files\n",
    "        path = os.path.join(cwd, folder_name)\n",
    "        if folder_name not in os.listdir():\n",
    "            os.mkdir(path)\n",
    "        # Unload zip into the new folder\n",
    "        response = urllib.request.urlopen(url) # Get a response\n",
    "        zip_folder = zipfile.ZipFile(BytesIO(response.read())) # Read Response\n",
    "        zip_folder.extractall(path=path) # Extract files\n",
    "        zip_folder.close() # Close zip object\n",
    "    else:\n",
    "        print('Error Extracting: Invalid Input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Minnesota Geospatial Commons](https://gisdata.mn.gov/content/?q=help/api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data from Minnesota Geospatial Commons\n",
    "\n",
    "## Twin Cities Metro Boundaries & AADT - Downloaded from MN GeospatialCommons gisdata.mn.gov  (~ 6mb)\n",
    "\n",
    "boundary_url = \"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/bdry_census2010counties_ctus/shp_bdry_census2010counties_ctus.zip\"\n",
    "aadt_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dot/trans_aadt_traffic_segments/shp_trans_aadt_traffic_segments.zip'\n",
    "\n",
    "extract_zip_from_url(boundary_url)\n",
    "extract_zip_from_url(aadt_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Local Filepaths\n",
    "\n",
    "boundary_folder = boundary_url.split('/')[-1][:-4] # Get folder name (last part of address minus .zip)\n",
    "boundary_file = 'Census2010CountiesAndCTUs.shp'\n",
    "boundary_path = os.path.join(boundary_folder, boundary_file)\n",
    "\n",
    "aadt_folder = aadt_url.split('/')[-1][:-4]\n",
    "aadt_file = 'Annual_Average_Daily_Traffic_Segments_in_Minnesota.shp'\n",
    "aadt_path = os.path.join(aadt_folder, aadt_file)\n",
    "\n",
    "# Load into geopandas\n",
    "\n",
    "ctus = gpd.read_file(boundary_path) # Municipal boundaries\n",
    "aadt = gpd.read_file(aadt_path) # Traffic Segments with Current Annual Average Daily Traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Google Places](https://developers.google.com/maps/documentation/places/web-service/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_places_to_gdf(url, api):\n",
    "\n",
    "    ''' This function will take a url to the goole api and convert the response into a geodataframe.\n",
    "        It does NOT work with a \"find place\" search\n",
    "        \n",
    "    # To Download Data from Google Places API\n",
    "    # Must create a project on google API Console - https://console.developers.google.com/\n",
    "    # Enable Google Places API\n",
    "    # They need a credit card...\n",
    "\n",
    "    # Base of the url = https://maps.googleapis.com/maps/api/place/details/output?parameters\n",
    "    '''\n",
    "    \n",
    "    api_url = url + '&key=' + api\n",
    "    \n",
    "    response = requests.request(\"GET\", api_url) # Get request\n",
    "    \n",
    "    results = response.json()['results'] # Read request as a dictionary\n",
    "    df = pd.DataFrame(results) # Convert Dictionary to DataFrame (without correct \"geometry\" column)\n",
    "    \n",
    "    # Get lat/longs for geometry column\n",
    "\n",
    "    df['x'] = None # Initialize column for Longitude\n",
    "    df['y'] = None # Initialize column for Latitude\n",
    "\n",
    "    for i, row in df.iterrows(): # Iterate through rows\n",
    "        df.loc[i,'x'] = row.geometry['location']['lng'] # Get info\n",
    "        df.loc[i,'y'] = row.geometry['location']['lat']\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df.drop(columns='geometry'),\n",
    "                           geometry = gpd.points_from_xy(df['x'], df['y']),\n",
    "                           crs = 'EPSG:4326')\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your Google API key: ·······································\n"
     ]
    }
   ],
   "source": [
    "api = getpass.getpass('Please enter your Google API key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for primary schools nearby intersection of 94 and 35W\n",
    "\n",
    "url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json?location=44.965676%2C-93.259512&rankby=distance&type=primary_school&keyword=school'\n",
    "schools = google_places_to_gdf(url, api)\n",
    "\n",
    "# Search for Municipal Pools in North Dakota\n",
    "\n",
    "url = 'https://maps.googleapis.com/maps/api/place/textsearch/json?input=Municipal%20Pool%20in%20North%20Dakota&inputtype=textquery&locationbias=rectangle:45.951407,-104.048971|49,-96.561788'\n",
    "pools_nd = google_places_to_gdf(url, api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [NDAWN](https://ndawn.ndsu.nodak.edu//)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a csv from their api\n",
    "\n",
    "# Below Example: Monthly max/min/avg temp of Minot, ND for the past year\n",
    "# https://ndawn.ndsu.nodak.edu/table.csv?station=40&variable=mdmxt&variable=mdmnt&variable=mdavt&year=2022&ttype=monthly&quick_pick=1_y&begin_date=2021-09&count=12\n",
    "\n",
    "# This one gets max/min/avg temp for all stations for the past year\n",
    "url = 'https://ndawn.ndsu.nodak.edu/table.csv?station=78&station=111&station=98&station=174&station=142&station=138&station=161&station=9&station=10&station=118&station=56&station=11&station=12&station=58&station=13&station=84&station=55&station=7&station=87&station=14&station=15&station=96&station=16&station=137&station=124&station=143&station=17&station=85&station=140&station=134&station=18&station=136&station=65&station=104&station=99&station=19&station=129&station=20&station=101&station=81&station=21&station=97&station=22&station=75&station=2&station=172&station=139&station=23&station=62&station=86&station=24&station=89&station=126&station=93&station=90&station=25&station=83&station=107&station=156&station=77&station=26&station=70&station=127&station=27&station=132&station=28&station=29&station=30&station=31&station=102&station=32&station=119&station=4&station=80&station=33&station=59&station=105&station=82&station=34&station=72&station=135&station=35&station=76&station=120&station=141&station=109&station=36&station=79&station=71&station=37&station=38&station=39&station=130&station=73&station=40&station=41&station=54&station=69&station=113&station=128&station=42&station=43&station=103&station=116&station=88&station=114&station=3&station=163&station=64&station=115&station=67&station=44&station=133&station=106&station=100&station=121&station=45&station=46&station=61&station=66&station=74&station=60&station=125&station=8&station=47&station=122&station=108&station=5&station=152&station=48&station=68&station=49&station=50&station=91&station=117&station=63&station=150&station=51&station=6&station=52&station=92&station=112&station=131&station=123&station=95&station=53&station=57&station=149&station=148&station=110&variable=mdmxt&variable=mdmnt&variable=mdavt&year=2022&ttype=monthly&quick_pick=1_y&begin_date=2021-09&count=12'\n",
    "response = requests.request('GET', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where CSV Starts in the response\n",
    "# The beginning is a header describing what NDAWN is and such\n",
    "\n",
    "start = response.text.find('Station Name')\n",
    "\n",
    "# Decoding string\n",
    "\n",
    "decoding = StringIO(response.text[start:])\n",
    "\n",
    "# Read into Pandas\n",
    "\n",
    "temps = pd.read_csv(decoding).iloc[1:,:] # Skipping first entry, it just gives the units of each column\n",
    "\n",
    "# Spatialize\n",
    "\n",
    "temps_gdf = gpd.GeoDataFrame(temps,\n",
    "                             geometry = gpd.points_from_xy(x = temps.Longitude, y = temps.Latitude),\n",
    "                             crs = 'EPSG:4326')\n",
    "\n",
    "# Find the stations/months that had pool-worthy days\n",
    "\n",
    "pool_days = temps_gdf[pd.to_numeric(temps_gdf['Max Temp']) > 80] # Months/stations that had > 80 degree days\n",
    "\n",
    "# Group by unique stations\n",
    "\n",
    "pool_days_gp = pool_days.groupby('Station Name').agg({'geometry':['unique'],\n",
    "                                       'Month':['unique']})\n",
    "\n",
    "# Get a new geodataframe with station name and months they were pool-worthy\n",
    "\n",
    "pool_days_by_sta = gpd.GeoDataFrame(pool_days_gp.Month, \n",
    "                                    geometry = pool_days_gp.geometry.unique.apply(lambda x:x[0]),\n",
    "                                    crs = temps_gdf.crs).rename(columns = {'unique':'Months'})\n",
    "\n",
    "# Convert np.arrays in Months into lists for saving in the future\n",
    "\n",
    "pool_days_by_sta['Months'] = pool_days_by_sta.Months.apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatially Join Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CTU dataset is in the  epsg:26915  CRS.\n",
      "The AADT dataset is in the  epsg:26915  CRS.\n",
      "They are in the same CRS, UTM 15N\n",
      "   index  SEQUENCE_N   FROM_DATE     TO_DATE ROUTE_LABE   STREET_NAM  \\\n",
      "0  20464       32942  1997-01-01  4000-01-01    CSAH 86    30th St W   \n",
      "1  26143       42156  1998-01-01  4000-01-01    CSAH 91  Natchez Ave   \n",
      "1  26143       42156  1998-01-01  4000-01-01    CSAH 91  Natchez Ave   \n",
      "2  26147       42160  1998-01-01  4000-01-01     CSAH 2   260th St E   \n",
      "2  26147       42160  1998-01-01  4000-01-01     CSAH 2   260th St E   \n",
      "\n",
      "                             LOCATION_D  VEHICLE_CL  \\\n",
      "0                  E OF SCOTT CO CSAH91           0   \n",
      "1  S OF CSAH2 (MAIN ST/260th ST E) ELKO           0   \n",
      "1  S OF CSAH2 (MAIN ST/260th ST E) ELKO           0   \n",
      "2      E OF CSAH91 (NATCHEZ AV) IN ELKO           0   \n",
      "2      E OF CSAH91 (NATCHEZ AV) IN ELKO           0   \n",
      "\n",
      "                            DAILY_FACT                           SEASONAL_F  \\\n",
      "0                 11 - Sim WkDay/WkEnd                 11 - Sim WkDay/WkEnd   \n",
      "1  17 - Mod High WkEnd/Mod High Summer  17 - Mod High WkEnd/Mod High Summer   \n",
      "1  17 - Mod High WkEnd/Mod High Summer  17 - Mod High WkEnd/Mod High Summer   \n",
      "2                 11 - Sim WkDay/WkEnd                 11 - Sim WkDay/WkEnd   \n",
      "2                 11 - Sim WkDay/WkEnd                 11 - Sim WkDay/WkEnd   \n",
      "\n",
      "   ...           COCTU_DESC  CO_CODE  CO_NAME   CTU_ID CTU_ID_CEN  CTU_CODE  \\\n",
      "0  ...  New Market Township      139    Scott   665104   00665104     45754   \n",
      "1  ...      Elko New Market      139    Scott  2394658   02394658     18662   \n",
      "1  ...  New Market Township      139    Scott   665104   00665104     45754   \n",
      "2  ...      Elko New Market      139    Scott  2394658   02394658     18662   \n",
      "2  ...  New Market Township      139    Scott   665104   00665104     45754   \n",
      "\n",
      "          CTU_NAME  COMCD_CENS    Shape_Leng    Shape_Area  \n",
      "0  New Market Twp.      139065  63762.012331  8.436207e+07  \n",
      "1  Elko New Market           0  25161.245886  8.456836e+06  \n",
      "1  New Market Twp.      139065  63762.012331  8.436207e+07  \n",
      "2  Elko New Market           0  25161.245886  8.456836e+06  \n",
      "2  New Market Twp.      139065  63762.012331  8.436207e+07  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Spatially Join Municipal Boundaries to Roads\n",
    "\n",
    "# Check CRS\n",
    "\n",
    "print('The CTU dataset is in the ', ctus.crs, ' CRS.')\n",
    "print('The AADT dataset is in the ', aadt.crs, ' CRS.')\n",
    "if ctus.crs == aadt.crs:\n",
    "    print('They are in the same CRS, UTM 15N')\n",
    "else:\n",
    "    print('Transforming...')\n",
    "    ctus = ctus.to_crs(aadt.crs)\n",
    "\n",
    "# Clip AADT to CTU boundary\n",
    "\n",
    "aadt_clipped = gpd.clip(aadt, ctus).reset_index()\n",
    "\n",
    "# Spatially Join (Road segments keep their geometry and get Municipality information)\n",
    "\n",
    "aadt_w_ctus = gpd.sjoin(left_df = aadt_clipped, right_df = ctus, how = 'left')\n",
    "\n",
    "print(aadt_w_ctus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  business_status                                               icon  \\\n",
      "0     OPERATIONAL  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "1     OPERATIONAL  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "2     OPERATIONAL  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "3     OPERATIONAL  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "4     OPERATIONAL  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "\n",
      "  icon_background_color                                 icon_mask_base_uri  \\\n",
      "0               #7B9EB0  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "1               #7B9EB0  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "2               #7B9EB0  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "3               #7B9EB0  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "4               #7B9EB0  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "\n",
      "                                       name        opening_hours  \\\n",
      "0             Emerson Dual Language School.   {'open_now': True}   \n",
      "1  Whittier International Elementary School  {'open_now': False}   \n",
      "2                     MTS Elementary School   {'open_now': True}   \n",
      "3                  Seward Montessori School   {'open_now': True}   \n",
      "4      Minnesota Transitions Charter School   {'open_now': True}   \n",
      "\n",
      "                                              photos  \\\n",
      "0  [{'height': 720, 'html_attributions': ['<a hre...   \n",
      "1  [{'height': 1083, 'html_attributions': ['<a hr...   \n",
      "2  [{'height': 2589, 'html_attributions': ['<a hr...   \n",
      "3  [{'height': 3120, 'html_attributions': ['<a hr...   \n",
      "4  [{'height': 469, 'html_attributions': ['<a hre...   \n",
      "\n",
      "                      place_id  \\\n",
      "0  ChIJoeQ3mMAys1IR34vz2p5yCME   \n",
      "1  ChIJzc00EqUqs1IRJ27p2nSdRfs   \n",
      "2  ChIJk_77Kyko9ocRDsDBuMaPNIE   \n",
      "3  ChIJ_6xzdTEts1IRQwUshM52aqw   \n",
      "4  ChIJpdfBFCEo9ocRIbaoIqN-L1A   \n",
      "\n",
      "                                           plus_code  rating  ...  \\\n",
      "0  {'compound_code': 'XP99+8R Minneapolis, Minnes...     4.7  ...   \n",
      "1  {'compound_code': 'XP38+VC Minneapolis, Minnes...     3.2  ...   \n",
      "2  {'compound_code': 'XQ48+GJ Minneapolis, Minnes...     3.9  ...   \n",
      "3  {'compound_code': 'XQ69+4Q Minneapolis, Minnes...     3.9  ...   \n",
      "4  {'compound_code': 'XQ26+6V Minneapolis, Minnes...     5.0  ...   \n",
      "\n",
      "                       LOCATION_D VEHICLE_CL               DAILY_FACT  \\\n",
      "0  W of MSAS 159 (La Salle Ave S)          0  9 - High WkDay/Commuter   \n",
      "1             E OF GARFIELD AVE S          0     11 - Sim WkDay/WkEnd   \n",
      "2        N OF MSAS238 (E 25TH ST)          0     11 - Sim WkDay/WkEnd   \n",
      "3        N OF MSAS238 (E 25TH ST)          0     11 - Sim WkDay/WkEnd   \n",
      "4              CSAH 3 TO NB MN 55          0     11 - Sim WkDay/WkEnd   \n",
      "\n",
      "                SEASONAL_F                        AXLE_FACTO CURRENT_YE  \\\n",
      "0  9 - High WkDay/Commuter           5-Urban Major Collector       2018   \n",
      "1     11 - Sim WkDay/WkEnd            4-Urban Minor Arterial       2019   \n",
      "2     11 - Sim WkDay/WkEnd           5-Urban Major Collector       2020   \n",
      "3     11 - Sim WkDay/WkEnd           5-Urban Major Collector       2020   \n",
      "4     11 - Sim WkDay/WkEnd  3-Urban Principal Arterial Other       2021   \n",
      "\n",
      "  CURRENT_VO                                         AADT_COMME  DATA_TYPE  \\\n",
      "0     7800.0                                         18 New Loc          A   \n",
      "1     5900.0  15 Per Cty Eng, 12 Est Hist (11 Cnt), Avg Hist...          A   \n",
      "2     1650.0                     20 COVID, 08 Est Hist (07 Cnt)          A   \n",
      "3     1650.0                     20 COVID, 08 Est Hist (07 Cnt)          A   \n",
      "4     1101.0       21 Lim Hist, 20 Baseline, No Factor (12 Cnt)          A   \n",
      "\n",
      "    SHAPE_Leng  \n",
      "0   312.009873  \n",
      "1   908.629363  \n",
      "2  1192.519278  \n",
      "3  1192.519278  \n",
      "4   532.203115  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Spatially join schools to the roads from above \n",
    "\n",
    "# Schools keep their geometry and get road information\n",
    "\n",
    "schools_utm = schools.to_crs(aadt.crs) # Change to correct CRS\n",
    "schools_w_roads = gpd.sjoin_nearest(schools_utm, aadt) # Join \n",
    "\n",
    "print(schools_w_roads.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Months                     geometry  index_right  \\\n",
      "Station Name                                                          \n",
      "Garrison       [7.0, 8.0]  POINT (-101.67955 47.71023)            5   \n",
      "Minot          [7.0, 8.0]  POINT (-101.30797 48.18043)           10   \n",
      "Medicine Hole  [7.0, 8.0]  POINT (-102.99209 47.55994)           16   \n",
      "Rice           [6.0, 7.0]   POINT (-94.26182 45.79384)            2   \n",
      "Turtle Lake    [7.0, 8.0]  POINT (-100.91529 47.56793)            5   \n",
      "\n",
      "              business_status  \\\n",
      "Station Name                    \n",
      "Garrison          OPERATIONAL   \n",
      "Minot             OPERATIONAL   \n",
      "Medicine Hole     OPERATIONAL   \n",
      "Rice              OPERATIONAL   \n",
      "Turtle Lake       OPERATIONAL   \n",
      "\n",
      "                                               formatted_address  \\\n",
      "Station Name                                                       \n",
      "Garrison        443 1st St NE, Garrison, ND 58540, United States   \n",
      "Minot              E Central Ave, Minot, ND 58701, United States   \n",
      "Medicine Hole  City Pool, 3385 Pool Dr, Medora, ND 58645, Uni...   \n",
      "Rice           85 Rj Hughes Dr, Wahpeton, ND 58075, United St...   \n",
      "Turtle Lake     443 1st St NE, Garrison, ND 58540, United States   \n",
      "\n",
      "                                                            icon  \\\n",
      "Station Name                                                       \n",
      "Garrison       https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "Minot          https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "Medicine Hole  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "Rice           https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "Turtle Lake    https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "\n",
      "              icon_background_color  \\\n",
      "Station Name                          \n",
      "Garrison                    #7B9EB0   \n",
      "Minot                       #7B9EB0   \n",
      "Medicine Hole               #7B9EB0   \n",
      "Rice                        #7B9EB0   \n",
      "Turtle Lake                 #7B9EB0   \n",
      "\n",
      "                                              icon_mask_base_uri  \\\n",
      "Station Name                                                       \n",
      "Garrison       https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "Minot          https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "Medicine Hole  https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "Rice           https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "Turtle Lake    https://maps.gstatic.com/mapfiles/place_api/ic...   \n",
      "\n",
      "                                         name        opening_hours  \\\n",
      "Station Name                                                         \n",
      "Garrison       Garrison Community Swimming Pl                  NaN   \n",
      "Minot            Roosevelt Park Swimming Pool  {'open_now': False}   \n",
      "Medicine Hole            Medora Swimming Pool  {'open_now': False}   \n",
      "Rice                 Chahinkapa Swimming Pool  {'open_now': False}   \n",
      "Turtle Lake    Garrison Community Swimming Pl                  NaN   \n",
      "\n",
      "                                  place_id  \\\n",
      "Station Name                                 \n",
      "Garrison       ChIJ2UuabI7y2FIR_yE8JwOT11w   \n",
      "Minot          ChIJqTT2FLQr31IRbfpjZqAOrWY   \n",
      "Medicine Hole  ChIJh2wAD4HpJVMR7TIO4vbgSjM   \n",
      "Rice           ChIJnzzxiyBJyVIRkmL3HYAYZ34   \n",
      "Turtle Lake    ChIJ2UuabI7y2FIR_yE8JwOT11w   \n",
      "\n",
      "                                                       plus_code  rating  \\\n",
      "Station Name                                                               \n",
      "Garrison       {'compound_code': 'MH4J+H8 Garrison, North Dak...     4.5   \n",
      "Minot          {'compound_code': '6PPC+VJ Minot, North Dakota...     4.5   \n",
      "Medicine Hole  {'compound_code': 'WF98+QW Medora, North Dakot...     4.7   \n",
      "Rice           {'compound_code': '7CC2+7H Wahpeton, North Dak...     4.2   \n",
      "Turtle Lake    {'compound_code': 'MH4J+H8 Garrison, North Dak...     4.5   \n",
      "\n",
      "                                 reference  \\\n",
      "Station Name                                 \n",
      "Garrison       ChIJ2UuabI7y2FIR_yE8JwOT11w   \n",
      "Minot          ChIJqTT2FLQr31IRbfpjZqAOrWY   \n",
      "Medicine Hole  ChIJh2wAD4HpJVMR7TIO4vbgSjM   \n",
      "Rice           ChIJnzzxiyBJyVIRkmL3HYAYZ34   \n",
      "Turtle Lake    ChIJ2UuabI7y2FIR_yE8JwOT11w   \n",
      "\n",
      "                                            types  user_ratings_total  \\\n",
      "Station Name                                                            \n",
      "Garrison       [point_of_interest, establishment]                   2   \n",
      "Minot          [point_of_interest, establishment]                  52   \n",
      "Medicine Hole  [point_of_interest, establishment]                  11   \n",
      "Rice           [point_of_interest, establishment]                  60   \n",
      "Turtle Lake    [point_of_interest, establishment]                   2   \n",
      "\n",
      "                                                          photos           x  \\\n",
      "Station Name                                                                   \n",
      "Garrison       [{'height': 964, 'html_attributions': ['<a hre... -101.419128   \n",
      "Minot          [{'height': 4032, 'html_attributions': ['<a hr... -101.278452   \n",
      "Medicine Hole  [{'height': 3024, 'html_attributions': ['<a hr... -103.532705   \n",
      "Rice           [{'height': 4160, 'html_attributions': ['<a hr...  -96.598623   \n",
      "Turtle Lake    [{'height': 964, 'html_attributions': ['<a hre... -101.419128   \n",
      "\n",
      "                       y  \n",
      "Station Name              \n",
      "Garrison       47.656374  \n",
      "Minot          48.237138  \n",
      "Medicine Hole  46.919497  \n",
      "Rice           46.270698  \n",
      "Turtle Lake    47.656374  \n"
     ]
    }
   ],
   "source": [
    "# Spatially join NDAWN stations to pools in ND (they're in the same CRS)\n",
    "# I know they should be in a UTM CRS for these calculations... But accuracy isn't as important here\n",
    "# Stations keep their geometry and gain nearest pool info\n",
    "\n",
    "stations_w_pools = gpd.sjoin_nearest(pool_days_by_sta, pools_nd) # Join \n",
    "\n",
    "print(stations_w_pools.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Joined Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The spatially joined datasets were:\n",
    "# aadt_w_ctus, schools_w_roads, and stations_w_pools\n",
    "# Now to save them as geojsons add them into a arcpro geodatabase\n",
    "\n",
    "# Save GeoDataFrames as geojsons\n",
    "\n",
    "datasets = [aadt_w_ctus, schools_w_roads, stations_w_pools]\n",
    "names = ['roads_w_ctus.geojson', 'schools_w_roads.geojson', 'stations_w_pools.geojson']\n",
    "\n",
    "# Iterate through datasets\n",
    "\n",
    "for i, data in enumerate(datasets):\n",
    "    \n",
    "    path = os.path.join('Results', names[i]) # Save Path\n",
    "    \n",
    "    if 'photos' in data.columns: # Remove photos column (lists within dictionary - tough to save...)\n",
    "        data = data.drop(columns=['photos'])\n",
    "        \n",
    "    # Make all other lists into dictionaries\n",
    "    \n",
    "    for column in data.columns:\n",
    "        if column != 'geometry':\n",
    "            if (type([]) in data[column].apply(lambda x: type(x)).values): # If a list is in the series\n",
    "                for i, row in data.iterrows(): # Iterate through elements\n",
    "                    if (type(row[column]) == list): # If a list\n",
    "                        l = data.loc[i, column] # Get the list\n",
    "                        new_l = dict(zip(range(len(l)), l)) # Convert to dictionary\n",
    "                        data.loc[[i], [column]] = new_l # Replace as dictionary\n",
    "                        \n",
    "    data.to_file(path) # Save File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to GeoDataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Arcpy\n",
    "\n",
    "import arcpy\n",
    "\n",
    "# Set Working Directory\n",
    "\n",
    "arcpy.env.workspace = os.getcwd() + 'Arc1_Lab1.gdb'\n",
    "\n",
    "# Add Geojsons to GeoDataBase\n",
    "\n",
    "files = os.listdir('Results')\n",
    "\n",
    "for file in files:\n",
    "    path = os.path.join('Results', file)\n",
    "    feature_name = file.split('.')[0]\n",
    "    \n",
    "    if feature_name == 'roads_w_ctus':\n",
    "        geom_type = 'Polyline'\n",
    "    else:\n",
    "        geom_type = 'Point'\n",
    "        \n",
    "    arcpy.JSONToFeatures_conversion(path, os.path.join(\"Arc1_Lab1.gdb\", feature_name), geom_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
